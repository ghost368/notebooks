{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596658277090",
   "display_name": "Python 3.8.3 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba - just-in-time compiler for Python, works best with numpy and loops\n",
    "\n",
    "**JIT compilation**:\n",
    "\n",
    "A JIT compiler runs after the program has started and compiles the code (usually bytecode or some kind of VM instructions) on the fly (or just-in-time, as it's called) into a form that's usually faster, typically the host CPU's native instruction set. A JIT has access to dynamic runtime information whereas a standard compiler doesn't and can make better optimizations like inlining functions that are used frequently.\n",
    "\n",
    "This is in contrast to a traditional compiler that compiles all the code to machine language before the program is first run.\n",
    "\n",
    "GIL means that a python interpreter can only work with a single thread at a time. Threads work in parallel but share the same memory heap (unlike processes which run independently). So there's risk of race condition for threads and that's why GIL was imposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  9.  10.  11.  12.  13.  14.  15.  16.  17.  18.]\n [ 19.  20.  21.  22.  23.  24.  25.  26.  27.  28.]\n [ 29.  30.  31.  32.  33.  34.  35.  36.  37.  38.]\n [ 39.  40.  41.  42.  43.  44.  45.  46.  47.  48.]\n [ 49.  50.  51.  52.  53.  54.  55.  56.  57.  58.]\n [ 59.  60.  61.  62.  63.  64.  65.  66.  67.  68.]\n [ 69.  70.  71.  72.  73.  74.  75.  76.  77.  78.]\n [ 79.  80.  81.  82.  83.  84.  85.  86.  87.  88.]\n [ 89.  90.  91.  92.  93.  94.  95.  96.  97.  98.]\n [ 99. 100. 101. 102. 103. 104. 105. 106. 107. 108.]]\n"
    }
   ],
   "source": [
    "# numba nopython mode support only numpy\n",
    "\n",
    "# nb.jit - JIT compilator\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@nb.jit(nopython=True) # set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def go_fast(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "    return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "print(go_fast(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@jit will try first to apply nopython mode, then switch to object mode if fail. Recommended to directly use @njit (same as nopython=True) to make sure the code runs w/o python (and there's actually performance improvement)\n",
    "\n",
    "First time njit function call adds some overhead due to compilation, when it's compiled - it's cached and the subsequent calls will be without overhead and hopefully faster than the python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 4, 6])"
     },
     "metadata": {},
     "execution_count": 14
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 4, 6])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# @nb.vectorize will produce numpy ufunc (i.e. a vectorized function, same as np.vectorize output)\n",
    "# used when we need to decorate single argument function both with @njit and vectorize it\n",
    "\n",
    "import math\n",
    "arr = np.array([1.2, 3.2, 5.4])\n",
    "\n",
    "# math.ceil(arr)  # won't work since math.ceil is not ufunc\n",
    "arr_ceil = np.vectorize(math.ceil)\n",
    "arr_ceil(arr)\n",
    "\n",
    "# arr_ceil_nb = nb.njit(arr_ceil)  # won't work\n",
    "\n",
    "@nb.vectorize\n",
    "def arr_ceil_nb(x):\n",
    "    return math.ceil(x)\n",
    "\n",
    "arr_ceil_nb(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eager compilation - specify signature, types must be imported from numba\n",
    "from numba import int32\n",
    "\n",
    "@nb.njit(int32(int32, int32))\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "\n",
    "# signature definition: int32, int64, float64 etc, void for no return func, int64[:], int64[:,:] etc for arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# certain number of functions from numpy and math are supported by numba and can be compiled\n",
    "# otherwise only compiled user functions can be used inside other compiled functions (in nopython mode of course)\n",
    "@nb.njit\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "@nb.njit\n",
    "def hypot(x, y):\n",
    "    return math.sqrt(square(x) + square(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python interpreter uses GIL, if a function is compiled by numba in nopython mode (njit), it's no longer necessary to hold Python's GIL.\n",
    "\n",
    "* Thus can pass ```nogil``` bool argument to @jit or @njit\n",
    "* nogil mode can have better performance in multi-core systems, but has to take care about race condition etc (if that's an issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguments of @jit\n",
    "* nopython\n",
    "* nogil : release GIL if True\n",
    "* cache : if True then cache compiled function in a file at the first fun\n",
    "* parallel : enables parallelization for certain type of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel : at the moment only works for CPUs\n",
    "\n",
    "# some operations are naturally suitable for parallelization (like adding scalar to an array) - if parallel=True numba with automatically detect and parallelize such function parts\n",
    "\n",
    "# can use numba.prange to make a loop parallel (loop must not have cross-dependencies)\n",
    "# in python mode prange is just an alias for range\n",
    "# best to use with nogil=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 1, 2],\n       [3, 4, 5]])"
     },
     "metadata": {},
     "execution_count": 25
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[10, 11, 12],\n       [13, 14, 15]])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# can pass multiple possible signatures in a list\n",
    "from numba import int32, int64, float32, float64\n",
    "\n",
    "@nb.vectorize([int32(int32, int32),\n",
    "            int64(int64, int64),\n",
    "            float32(float32, float32),\n",
    "            float64(float64, float64)])\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "\n",
    "# generalize vectorized functions (will be applied to sub-arrays)\n",
    "@nb.guvectorize([(int64[:], int64, int64[:])], '(n),()->(n)')\n",
    "def g(x, y, res):\n",
    "    for i in range(x.shape[0]):\n",
    "        res[i] = x[i] + y\n",
    "\n",
    "arr = np.arange(6).reshape(2, 3)\n",
    "arr\n",
    "g(arr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### both @nb.vectorize and @nb.guvectorize support nopython=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9.0"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# can use structured arrays inside jitted functions (dicts are on the other hand : not supported)\n",
    "# structured arrays will often help when we separate and jit numerical part of a function on a pandas df\n",
    "# (and typically already have column names, etc)\n",
    "\n",
    "@nb.njit\n",
    "def f(x):\n",
    "    return x['a'].sum()\n",
    "\n",
    "arr = np.array([(4, 5), (3, 6), (2, 3)], dtype=np.dtype([('a', 'f8'), ('b', 'f8')]))\n",
    "\n",
    "f(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([4., 3., 2.])"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}