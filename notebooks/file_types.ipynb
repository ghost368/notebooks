{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv, xls, hdf5, ncdf, json, pkl, pyarrow and parquet, gzip,  etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv is plain text format (not binary), data saved as plain text separated by commas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (?) pandas .memory_usage() vs space in file on disk for different formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import pandas as pd\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMAND_START_TIME = None\n",
    "\n",
    "def tic():\n",
    "    global COMMAND_START_TIME\n",
    "    COMMAND_START_TIME = time.time()\n",
    "\n",
    "def toc(name='Execution time'):\n",
    "    global COMMAND_START_TIME\n",
    "    print(f'\\n ---------- {name}:  {time.time() - COMMAND_START_TIME} seconds \\n')\n",
    "    COMMAND_START_TIME = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>J</th>\n",
       "      <th>H</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>-1.003622</td>\n",
       "      <td>-0.049134</td>\n",
       "      <td>-0.326186</td>\n",
       "      <td>0.062108</td>\n",
       "      <td>-0.057368</td>\n",
       "      <td>-1.368083</td>\n",
       "      <td>-0.780119</td>\n",
       "      <td>0.914958</td>\n",
       "      <td>1.676413</td>\n",
       "      <td>1.831727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:05:00</th>\n",
       "      <td>-0.118157</td>\n",
       "      <td>1.130713</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>1.269853</td>\n",
       "      <td>0.488006</td>\n",
       "      <td>-0.210061</td>\n",
       "      <td>0.555004</td>\n",
       "      <td>0.114502</td>\n",
       "      <td>0.084040</td>\n",
       "      <td>0.460183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:10:00</th>\n",
       "      <td>-1.048491</td>\n",
       "      <td>0.303878</td>\n",
       "      <td>-1.520755</td>\n",
       "      <td>1.217532</td>\n",
       "      <td>-1.851124</td>\n",
       "      <td>-0.155474</td>\n",
       "      <td>-0.438002</td>\n",
       "      <td>-0.092491</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>-0.812130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:15:00</th>\n",
       "      <td>-1.323914</td>\n",
       "      <td>-0.759893</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>-0.372727</td>\n",
       "      <td>2.328100</td>\n",
       "      <td>-1.248215</td>\n",
       "      <td>1.750482</td>\n",
       "      <td>-0.954200</td>\n",
       "      <td>-1.900064</td>\n",
       "      <td>0.817214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:20:00</th>\n",
       "      <td>1.187695</td>\n",
       "      <td>-0.041976</td>\n",
       "      <td>1.172901</td>\n",
       "      <td>-0.385393</td>\n",
       "      <td>-0.151192</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>-0.492217</td>\n",
       "      <td>0.323543</td>\n",
       "      <td>0.682622</td>\n",
       "      <td>-0.013872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 04:55:00</th>\n",
       "      <td>0.953457</td>\n",
       "      <td>0.082534</td>\n",
       "      <td>-1.343335</td>\n",
       "      <td>0.410405</td>\n",
       "      <td>1.584895</td>\n",
       "      <td>0.128722</td>\n",
       "      <td>-0.381379</td>\n",
       "      <td>-0.553342</td>\n",
       "      <td>-0.545461</td>\n",
       "      <td>-0.900247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:00:00</th>\n",
       "      <td>2.117599</td>\n",
       "      <td>-0.219048</td>\n",
       "      <td>-0.346014</td>\n",
       "      <td>1.657786</td>\n",
       "      <td>-1.994065</td>\n",
       "      <td>0.633052</td>\n",
       "      <td>0.533565</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>-0.167526</td>\n",
       "      <td>1.809655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:05:00</th>\n",
       "      <td>0.297714</td>\n",
       "      <td>-0.905382</td>\n",
       "      <td>0.521154</td>\n",
       "      <td>-1.162442</td>\n",
       "      <td>0.824354</td>\n",
       "      <td>1.444755</td>\n",
       "      <td>-0.591865</td>\n",
       "      <td>0.164547</td>\n",
       "      <td>1.696901</td>\n",
       "      <td>0.839050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:10:00</th>\n",
       "      <td>-1.156262</td>\n",
       "      <td>1.021879</td>\n",
       "      <td>1.277241</td>\n",
       "      <td>0.541207</td>\n",
       "      <td>-2.058688</td>\n",
       "      <td>2.813037</td>\n",
       "      <td>-1.353650</td>\n",
       "      <td>0.506960</td>\n",
       "      <td>-0.817149</td>\n",
       "      <td>0.321601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:15:00</th>\n",
       "      <td>2.027429</td>\n",
       "      <td>-0.460317</td>\n",
       "      <td>-1.891503</td>\n",
       "      <td>-0.799387</td>\n",
       "      <td>1.219440</td>\n",
       "      <td>-1.525655</td>\n",
       "      <td>0.964943</td>\n",
       "      <td>-1.774367</td>\n",
       "      <td>-1.267772</td>\n",
       "      <td>-0.137690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            A         B         C         D         E  \\\n",
       "2010-01-01 00:00:00 -1.003622 -0.049134 -0.326186  0.062108 -0.057368   \n",
       "2010-01-01 00:05:00 -0.118157  1.130713  0.004049  1.269853  0.488006   \n",
       "2010-01-01 00:10:00 -1.048491  0.303878 -1.520755  1.217532 -1.851124   \n",
       "2010-01-01 00:15:00 -1.323914 -0.759893  0.059542 -0.372727  2.328100   \n",
       "2010-01-01 00:20:00  1.187695 -0.041976  1.172901 -0.385393 -0.151192   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2019-07-05 04:55:00  0.953457  0.082534 -1.343335  0.410405  1.584895   \n",
       "2019-07-05 05:00:00  2.117599 -0.219048 -0.346014  1.657786 -1.994065   \n",
       "2019-07-05 05:05:00  0.297714 -0.905382  0.521154 -1.162442  0.824354   \n",
       "2019-07-05 05:10:00 -1.156262  1.021879  1.277241  0.541207 -2.058688   \n",
       "2019-07-05 05:15:00  2.027429 -0.460317 -1.891503 -0.799387  1.219440   \n",
       "\n",
       "                            F         J         H         K         L  \n",
       "2010-01-01 00:00:00 -1.368083 -0.780119  0.914958  1.676413  1.831727  \n",
       "2010-01-01 00:05:00 -0.210061  0.555004  0.114502  0.084040  0.460183  \n",
       "2010-01-01 00:10:00 -0.155474 -0.438002 -0.092491  0.549864 -0.812130  \n",
       "2010-01-01 00:15:00 -1.248215  1.750482 -0.954200 -1.900064  0.817214  \n",
       "2010-01-01 00:20:00  0.148803 -0.492217  0.323543  0.682622 -0.013872  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "2019-07-05 04:55:00  0.128722 -0.381379 -0.553342 -0.545461 -0.900247  \n",
       "2019-07-05 05:00:00  0.633052  0.533565  0.027153 -0.167526  1.809655  \n",
       "2019-07-05 05:05:00  1.444755 -0.591865  0.164547  1.696901  0.839050  \n",
       "2019-07-05 05:10:00  2.813037 -1.353650  0.506960 -0.817149  0.321601  \n",
       "2019-07-05 05:15:00 -1.525655  0.964943 -1.774367 -1.267772 -0.137690  \n",
       "\n",
       "[1000000 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rows = 1000000\n",
    "data = pd.DataFrame(rng.standard_normal(size=(nb_rows, 10)))\n",
    "data.memory_usage(0).sum()/1e6\n",
    "data.index = pd.date_range('2010-01-01', periods=nb_rows, freq='5min')\n",
    "data.columns = list('ABCDEFJHKL')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('/home/vlad/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- Save to csv:  10.68740701675415 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "data.to_csv(data_root/'data.csv')\n",
    "toc('Save to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- Pickle time:  0.46996498107910156 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "data.to_pickle(data_root/'data.pkl')\n",
    "toc('Pickle time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which format can save dtype, other metadata? provide custom access to a part of data (filtering before loading to disk)? (parquet)\n",
    "\n",
    "which formats are more and less stable in terms of python/package versions (pickle depends on python exact version etc)\n",
    "\n",
    "using buffers instead of files, any use cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- HDF5 time:  0.03911566734313965 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "data.to_hdf(data_root/'data.h5', key='data')\n",
    "toc('HDF5 time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- Parquet:  0.3030660152435303 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "data.to_parquet(data_root/'data.parquet', engine='pyarrow')\n",
    "toc('Parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- xarray NetCDF:  0.25287628173828125 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "xrvar = xr.DataArray(data)\n",
    "tic()\n",
    "xrvar.to_netcdf(data_root/'data.ncdf')\n",
    "toc('xarray NetCDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Field named 'index' not found or not unique in the schema.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-775e76f6ec71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'data.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ABF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2010'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parquet load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[1;32m    316\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_pandas_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         result = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         ).to_pandas()\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes)\u001b[0m\n\u001b[1;32m   1592\u001b[0m                 memory_map=memory_map, buffer_size=buffer_size)\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   1595\u001b[0m                             use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   1474\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Dataset._scanner\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Scanner.from_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset._populate_builder\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset._insert_implicit_casts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/daily/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Field named 'index' not found or not unique in the schema."
     ]
    }
   ],
   "source": [
    "tic()\n",
    "pd.read_parquet(data_root/'data.parquet', columns=list('ABF'), filters=[('index', '=', '2010')])\n",
    "toc('parquet load')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF 5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.HDFStore(data_root/'store.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- Execution time:  0.04439902305603027 seconds \n",
      "\n",
      "\n",
      " ---------- Execution time:  0.03567767143249512 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "s['data'] = data\n",
    "toc()\n",
    "\n",
    "sqr_data = data**2\n",
    "tic()\n",
    "s['sqr'] = sqr_data\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>J</th>\n",
       "      <th>H</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>-1.003622</td>\n",
       "      <td>-0.049134</td>\n",
       "      <td>-0.326186</td>\n",
       "      <td>0.062108</td>\n",
       "      <td>-0.057368</td>\n",
       "      <td>-1.368083</td>\n",
       "      <td>-0.780119</td>\n",
       "      <td>0.914958</td>\n",
       "      <td>1.676413</td>\n",
       "      <td>1.831728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:05:00</th>\n",
       "      <td>-0.118157</td>\n",
       "      <td>1.130713</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>1.269853</td>\n",
       "      <td>0.488006</td>\n",
       "      <td>-0.210061</td>\n",
       "      <td>0.555004</td>\n",
       "      <td>0.114502</td>\n",
       "      <td>0.084040</td>\n",
       "      <td>0.460183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:10:00</th>\n",
       "      <td>-1.048491</td>\n",
       "      <td>0.303878</td>\n",
       "      <td>-1.520755</td>\n",
       "      <td>1.217532</td>\n",
       "      <td>-1.851124</td>\n",
       "      <td>-0.155474</td>\n",
       "      <td>-0.438002</td>\n",
       "      <td>-0.092491</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>-0.812130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:15:00</th>\n",
       "      <td>-1.323914</td>\n",
       "      <td>-0.759893</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>-0.372727</td>\n",
       "      <td>2.328100</td>\n",
       "      <td>-1.248215</td>\n",
       "      <td>1.750482</td>\n",
       "      <td>-0.954199</td>\n",
       "      <td>-1.900064</td>\n",
       "      <td>0.817214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:20:00</th>\n",
       "      <td>1.187695</td>\n",
       "      <td>-0.041976</td>\n",
       "      <td>1.172901</td>\n",
       "      <td>-0.385393</td>\n",
       "      <td>-0.151192</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>-0.492217</td>\n",
       "      <td>0.323543</td>\n",
       "      <td>0.682622</td>\n",
       "      <td>-0.013872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 04:55:00</th>\n",
       "      <td>0.953457</td>\n",
       "      <td>0.082534</td>\n",
       "      <td>-1.343335</td>\n",
       "      <td>0.410405</td>\n",
       "      <td>1.584895</td>\n",
       "      <td>0.128722</td>\n",
       "      <td>-0.381379</td>\n",
       "      <td>-0.553342</td>\n",
       "      <td>-0.545461</td>\n",
       "      <td>-0.900247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:00:00</th>\n",
       "      <td>2.117599</td>\n",
       "      <td>-0.219048</td>\n",
       "      <td>-0.346014</td>\n",
       "      <td>1.657786</td>\n",
       "      <td>-1.994065</td>\n",
       "      <td>0.633052</td>\n",
       "      <td>0.533565</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>-0.167526</td>\n",
       "      <td>1.809655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:05:00</th>\n",
       "      <td>0.297714</td>\n",
       "      <td>-0.905382</td>\n",
       "      <td>0.521154</td>\n",
       "      <td>-1.162442</td>\n",
       "      <td>0.824354</td>\n",
       "      <td>1.444755</td>\n",
       "      <td>-0.591865</td>\n",
       "      <td>0.164547</td>\n",
       "      <td>1.696901</td>\n",
       "      <td>0.839050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:10:00</th>\n",
       "      <td>-1.156262</td>\n",
       "      <td>1.021879</td>\n",
       "      <td>1.277241</td>\n",
       "      <td>0.541207</td>\n",
       "      <td>-2.058688</td>\n",
       "      <td>2.813037</td>\n",
       "      <td>-1.353650</td>\n",
       "      <td>0.506960</td>\n",
       "      <td>-0.817149</td>\n",
       "      <td>0.321601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05 05:15:00</th>\n",
       "      <td>2.027430</td>\n",
       "      <td>-0.460317</td>\n",
       "      <td>-1.891503</td>\n",
       "      <td>-0.799387</td>\n",
       "      <td>1.219440</td>\n",
       "      <td>-1.525655</td>\n",
       "      <td>0.964943</td>\n",
       "      <td>-1.774367</td>\n",
       "      <td>-1.267772</td>\n",
       "      <td>-0.137690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            A         B         C         D         E  \\\n",
       "2010-01-01 00:00:00 -1.003622 -0.049134 -0.326186  0.062108 -0.057368   \n",
       "2010-01-01 00:05:00 -0.118157  1.130713  0.004049  1.269853  0.488006   \n",
       "2010-01-01 00:10:00 -1.048491  0.303878 -1.520755  1.217532 -1.851124   \n",
       "2010-01-01 00:15:00 -1.323914 -0.759893  0.059542 -0.372727  2.328100   \n",
       "2010-01-01 00:20:00  1.187695 -0.041976  1.172901 -0.385393 -0.151192   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2019-07-05 04:55:00  0.953457  0.082534 -1.343335  0.410405  1.584895   \n",
       "2019-07-05 05:00:00  2.117599 -0.219048 -0.346014  1.657786 -1.994065   \n",
       "2019-07-05 05:05:00  0.297714 -0.905382  0.521154 -1.162442  0.824354   \n",
       "2019-07-05 05:10:00 -1.156262  1.021879  1.277241  0.541207 -2.058688   \n",
       "2019-07-05 05:15:00  2.027430 -0.460317 -1.891503 -0.799387  1.219440   \n",
       "\n",
       "                            F         J         H         K         L  \n",
       "2010-01-01 00:00:00 -1.368083 -0.780119  0.914958  1.676413  1.831728  \n",
       "2010-01-01 00:05:00 -0.210061  0.555004  0.114502  0.084040  0.460183  \n",
       "2010-01-01 00:10:00 -0.155474 -0.438002 -0.092491  0.549864 -0.812130  \n",
       "2010-01-01 00:15:00 -1.248215  1.750482 -0.954199 -1.900064  0.817214  \n",
       "2010-01-01 00:20:00  0.148803 -0.492217  0.323543  0.682622 -0.013872  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "2019-07-05 04:55:00  0.128722 -0.381379 -0.553342 -0.545461 -0.900247  \n",
       "2019-07-05 05:00:00  0.633052  0.533565  0.027153 -0.167526  1.809655  \n",
       "2019-07-05 05:05:00  1.444755 -0.591865  0.164547  1.696901  0.839050  \n",
       "2019-07-05 05:10:00  2.813037 -1.353650  0.506960 -0.817149  0.321601  \n",
       "2019-07-05 05:15:00 -1.525655  0.964943 -1.774367 -1.267772 -0.137690  \n",
       "\n",
       "[1000000 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf(data_root/'data.h5', 'df')\n",
    "df_read = pd.read_hdf(data_root/'data.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: /home/vlad/tmp/data.h5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.HDFStore(data_root/'data.h5')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: /home/vlad/tmp/data.h5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas categorical variables (different in term of their storage)\n",
    "\n",
    "what is partitioning? how to use it with spark/parquet?\n",
    "\n",
    "which databases/storages support verion control (similar to different dated folders at GSA)\n",
    "\n",
    "Is dask useful at all, should I make a notebook on it?\n",
    "\n",
    "\n",
    "\"I have some experience with Parquet, some experience with how not to use it. I have two massive problems with it.\n",
    "\n",
    "I use it for a system where I only need a small slice of data at a time. Such as, amongst the last 10 years, only give me 2 days of data. This is a horrible usecase for parquet, this is what an index is for, the sort of thing you get with a database.\n",
    "\n",
    "I use the parquet to mirror a database which is constantly mutated. Again, horrible situation. You can't edit a record in parquet, it is append only. If I were using it correctly I would have mechanisms to allow for adding new modified records that will take precedence over the original documents.\"\n",
    "\n",
    "\n",
    "For SE even databases is super naive solution; read briefly about Kafka, etc, to understand the problematics\n",
    "\n",
    "databases with revision control (DB tables and list of revisions with old value, new value and timestamp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('daily': conda)",
   "language": "python",
   "name": "python38564bitdailyconda1b0ab4f1568045b9bd4bacd7ffcbdfae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
